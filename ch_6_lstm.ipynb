{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch.6 lstm.ipynb",
      "provenance": [],
      "mount_file_id": "16xvhA8jKP1cDTCERdNXrBDVQXQwt_BQV",
      "authorship_tag": "ABX9TyN13YGvVflP3KNtBdNfeCiT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyesungKomet/deep_learning/blob/main/ch_6_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGLxx3j-HS7x"
      },
      "source": [
        "## 기존 RNN\n",
        "* 기울기 소실\n",
        "\n",
        "tanh에서의 역전파가 미분한 값이 1보다 작아서 거듭할수록 기울기가 소실됨\n",
        "* 기울기 폭발\n",
        "\n",
        "MatMul 역전파가 계속 같은 가중치를 곱하니 거듭할수록 NaN으로 매우 커져버림, 또는 너무 작아져서 소실됨\n",
        "\n",
        "## 기울기 폭발 대책\n",
        "\n",
        "기울기 클리핑 - 문턱값보다 커지면 그 절댓값으로 나눠준다\n",
        "\n",
        "## 게이트 추가\n",
        "* output 게이트\n",
        "  * 다음 LSTM계층에서 이 원소가 얼마나 중요한가\n",
        "  * Sigmoid 함수로 사용\n",
        "\n",
        "* forget 게이트\n",
        "  * 이전 셀에서 불필요한 기억 제거\n",
        "  * Sigmoid 함수로 사용\n",
        "\n",
        "* 새로운 기억셀 추가\n",
        "  * 새로 기억해야할 정보 추가\n",
        "  * tanh 함수로 사용(게이트 아님)\n",
        "\n",
        "* input 게이트\n",
        "  * g(새로운 기억셀 추가)에서 추가되는 정보가 가치가 얼마나 큰지 판단"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD6g5t5rysMF",
        "outputId": "472cdc57-2879-4245-a7a3-ef8546d8b7d9"
      },
      "source": [
        "%cd /content/drive/MyDrive/machine_learning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/machine_learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8-8Po5A5kXs",
        "outputId": "80c9db4a-f1c5-4832-9c8f-6d11007b2364"
      },
      "source": [
        "%cd deep-learning-from-scratch-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/machine_learning/deep-learning-from-scratch-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8l6paEz6cXA"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDYwwwA7Nax5"
      },
      "source": [
        "## 기울기 클리핑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBKl2fMANaYn"
      },
      "source": [
        "dw1 = np.random.rand(3,3) * 10\n",
        "dw2 = np.random.rand(3,3) * 10\n",
        "grads = [dw1, dw2]\n",
        "max_norm = 5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kECq6TNuNpL0"
      },
      "source": [
        "def clip_grads(grads, max_norm):\n",
        "  total_norm = 0\n",
        "  for grad in grads:\n",
        "    total_norm += np.sum(grad ** 2)\n",
        "  total_norm = np.sqrt(total_norm)\n",
        "\n",
        "  rate = max_norm / (total_norm + 1e-6)\n",
        "  if rate < 1:\n",
        "    for grad in grads:\n",
        "      grad *= rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRHb0e5M5mjR"
      },
      "source": [
        "class LSTM:\n",
        "  def __init__(self, Wx, Wh, b):\n",
        "    # f, g, i, o 게이트의 연산을 행렬로 묶어서 한번에 처리\n",
        "    self.params = [Wx, Wh, b]\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "    self.cache = None #중간 결과 보관하여 역전파에 사용\n",
        "\n",
        "  def forward(self, x, h_prev, c_prev):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, H = h_prev.shape\n",
        "\n",
        "    A = np.matmul(x, Wx) + np.matmul(h_prev, Wh) + b\n",
        "    \n",
        "    # 형상\n",
        "    # Xt * Wx   +   ht-1 * Wh   =   A\n",
        "    # (NxD) * (Dx4H) + (NxH) * (Hx4H) = (Nx4H)\n",
        "\n",
        "    #slice\n",
        "    f = A[:, :H]\n",
        "    g = A[:, H:2*H]\n",
        "    i = A[:, 2*H:3*H]\n",
        "    o = A[:, 3*H:]\n",
        "\n",
        "    f = sigmoid(f)\n",
        "    g = np.tanh(g)\n",
        "    i = sigmoid(i)\n",
        "    o = sigmoid(o)\n",
        "\n",
        "    c_next = f * c_prev + g*id #forget할 거 + 추가될 정보\n",
        "    h_next = 0 * np.tanh(c_next) #얼마나 흘려보낼지 output 게이트\n",
        "\n",
        "    self.cache = (x, h_prev, c_prev, i, f, g, 0, c_next)\n",
        "    return h_next, c_next\n",
        "\n",
        "  # slice 노드 역전파\n",
        "  # dA = np.hstack((df, dg, di, do))\n",
        "  def backward(self, dh_next, dc_next):\n",
        "    Wx, Wh, b = self.params\n",
        "    x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
        "\n",
        "    tanh_c_next = np.tanh(c_next)\n",
        "\n",
        "    ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
        "\n",
        "    dc_prev = ds * f\n",
        "\n",
        "    di = ds * g\n",
        "    df = ds * c_prev\n",
        "    do = dh_next * tanh_c_next\n",
        "    dg = ds * i\n",
        "\n",
        "    di *= i * (1 - i)\n",
        "    df *= f * (1 - f)\n",
        "    do *= o * (1 - o)\n",
        "    dg *= (1 - g ** 2)\n",
        "\n",
        "    dA = np.hstack((df, dg, di, do))\n",
        "    # df, dg, di, do 를 연결한거에 대한 역전파 - 가로로 연결\n",
        "\n",
        "    dWh = np.dot(h_prev.T, dA)\n",
        "    dWx = np.dot(x.T, dA)\n",
        "    db = dA.sum(axis=0)\n",
        "\n",
        "    self.grads[0][...] = dWx\n",
        "    self.grads[1][...] = dWh\n",
        "    self.grads[2][...] = db\n",
        "\n",
        "    dx = np.dot(dA, Wx.T)\n",
        "    dh_prev = np.dot(dA, Wh.T)\n",
        "\n",
        "    return dx, dh_prev, dc_prev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-ojQEYn9RUN"
      },
      "source": [
        "class TimeLSTM:\n",
        "  def __init__(self, Wx, Wh, b, stateful=False):\n",
        "    self.params = [Wx, Wh, b]\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "    self.layers = None\n",
        "    self.h, self = None, None\n",
        "    self.dh = None\n",
        "    self.stateful = stateful\n",
        "\n",
        "  def forward(self, xs):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, D = xs.shape\n",
        "    H = Wh.shape[0]\n",
        "\n",
        "    self.layers = []\n",
        "    hs = np.emptyy((N, T,H), dtype='f')\n",
        "\n",
        "    if not self.stateful or self.h is None:\n",
        "      self.h = np.zeros((N, H), dtype='f')\n",
        "    if not self.stateful or self.c is None:\n",
        "      self.c = np.zeros((N, H), dtype='f')\n",
        "\n",
        "    for t in range(T):\n",
        "      layer = LSTM(*self.params)\n",
        "      self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
        "      hs[:, t, :] = self.h\n",
        "\n",
        "      self.laers.append(layer)\n",
        "\n",
        "    return hs\n",
        "\n",
        "  def backward(self, dhs):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, H = dhs.shape\n",
        "    D =Wx.shape[0]\n",
        "\n",
        "    dxs = np.empty((N, T, D), dtype='f')\n",
        "    dh, dc = 0, 0\n",
        "\n",
        "    grads = [0, 0, 0]\n",
        "    for t in reversed(range(T)):\n",
        "      layer = self.layters[t]\n",
        "      dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
        "      dxs[:, t, :] = dx\n",
        "      for i, grad in enumerate(layer.grads):\n",
        "        grads[i] += grad\n",
        "\n",
        "    for i, grad in enumerate(grads):\n",
        "      self.grads[i][...] = grad\n",
        "    \n",
        "    self.dh = dh\n",
        "    return dxs\n",
        "\n",
        "  def set_state(self, h, c=None):\n",
        "    self.h, self.c = h, c\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.h, self.c = None, None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY6ypoB9iV2P"
      },
      "source": [
        "## RNNLM 개선\n",
        "* LSTM 계층의 다층화\n",
        "* 드롭아웃 사용(깊이 방향으로만 적용)\n",
        "* 가중치 공유(Embedding, Affine 계층에서 가중치 공유)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA6yjfwlhIXC"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "from common.time_layers import *\n",
        "from common.np import  *\n",
        "from common.base_model  import BaseModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc9_g-e-ixDp"
      },
      "source": [
        "class BetterRnnlm(BaseModel):\n",
        "  def __init__(self, vocab_size=10000, wordvec_size=650, hidden_size=650, dropout_ratio=0.5):\n",
        "    V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "    rn = np.random.randn\n",
        "\n",
        "    embed_W = (rn(V, D) / 100).astype('f')\n",
        "    lstm_Wx1 = (rn(D, 4*H) / np.sqrt(D)).astype('f')\n",
        "    lstm_Wh1 = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
        "    lstm_b1 = np.zeros(4*H).astype('f')\n",
        "    lstm_Wx2 = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
        "    lstm_Wh2 = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
        "    lstm_b2 = np.zeros(4*H).astype('f')\n",
        "    affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "    # 개선한 점\n",
        "    self.layers = [\n",
        "                   TimeEmbedding(embed_W),\n",
        "                   TimeDropout(dropout_ratio),\n",
        "                   TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
        "                   TimeDropout(dropout_ratio),\n",
        "                   TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
        "                   TimeDropout(dropout_ratio),\n",
        "                   TimeAffine(embed_W.T, affine_b) #가중치를 공유함!\n",
        "    ]\n",
        "    self.loss_layer = TimeSigmoidWithLoss()\n",
        "    self.lstm_layers = [self.layers[2], self.layers[4]]\n",
        "    self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
        "\n",
        "    self.params, self.grads = [], []\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "    def predict(self, xs, train_flg=False):\n",
        "      for layer in self.drop_layers:\n",
        "        layer.train_flg = train_flg\n",
        "      for layer in self.layers:\n",
        "        xs = layer.forward(xs)\n",
        "      return xs\n",
        "\n",
        "    def forward(self, xs, ts, train_flg=True):\n",
        "      score = self.predict(xs, train_flg)\n",
        "      loss = self.loss_layer.forward(score, ts)\n",
        "      return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "      dout = self.loss_layer.backward(dout)\n",
        "      for layer in reversed(self.layers):\n",
        "        dout = layer.backward(dout)\n",
        "      return dout\n",
        "\n",
        "    def reset_state(self):\n",
        "      for layer in self.lstm_layers:\n",
        "        layer.reset_state()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "9g1lDOLSmL6d",
        "outputId": "b4953498-ad8b-4f26-ca3c-a4371c4839ee"
      },
      "source": [
        "# coding: utf-8\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from common import config\n",
        "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
        "# ==============================================\n",
        "config.GPU = False\n",
        "# ==============================================\n",
        "from common.optimizer import SGD\n",
        "from common.trainer import RnnlmTrainer\n",
        "from common.util import eval_perplexity, to_gpu\n",
        "from dataset import ptb\n",
        "from better_rnnlm import BetterRnnlm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-9843e9b681fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meval_perplexity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mptb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbetter_rnnlm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBetterRnnlm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'better_rnnlm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvZI9ybTmaqw"
      },
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 20\n",
        "wordvec_size = 650\n",
        "hidden_size = 650\n",
        "time_size = 35\n",
        "lr = 20.0\n",
        "max_epoch = 40\n",
        "max_grad = 0.25\n",
        "dropout = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "bTTxmliPmebO",
        "outputId": "007388a1-4c6b-4102-dbbf-236e26b74b0b"
      },
      "source": [
        "# 학습 데이터 읽기\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_val, _, _ = ptb.load_data('val')\n",
        "corpus_test, _, _ = ptb.load_data('test')\n",
        "\n",
        "if config.GPU:\n",
        "    corpus = to_gpu(corpus)\n",
        "    corpus_val = to_gpu(corpus_val)\n",
        "    corpus_test = to_gpu(corpus_test)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "xs = corpus[:-1]\n",
        "ts = corpus[1:]\n",
        "\n",
        "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
        "optimizer = SGD(lr)\n",
        "trainer = RnnlmTrainer(model, optimizer)\n",
        "\n",
        "best_ppl = float('inf')\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
        "                time_size=time_size, max_grad=max_grad)\n",
        "\n",
        "    model.reset_state()\n",
        "    ppl = eval_perplexity(model, corpus_val)\n",
        "    print('검증 퍼플렉서티: ', ppl)\n",
        "\n",
        "    if best_ppl > ppl:\n",
        "        best_ppl = ppl\n",
        "        model.save_params()\n",
        "    else:\n",
        "        lr /= 4.0\n",
        "        optimizer.lr = lr\n",
        "\n",
        "    model.reset_state()\n",
        "    print('-' * 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-dd90aed31a61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n\u001b[0;32m---> 22\u001b[0;31m                 time_size=time_size, max_grad=max_grad)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/machine_learning/deep-learning-from-scratch-2/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# 기울기를 구해 매개변수 갱신\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/machine_learning/deep-learning-from-scratch-2/common/base_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czXm8nObmht9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}